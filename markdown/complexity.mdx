# Time Complexity

By definition, Time complexity is the time taken by an algorithm/program to run as a function of the length of the input.

| Value                  | Complexity Name             |
| ---------------------- | --------------------------- |
| $$\text{O}(1)$$        | Constant Time Complexity    |
| $$\text{O}(\log{n})$$  | Logarithmic Time Complexity |
| $$\text{O}(n)$$        | Linear Time Complexity      |
| $$\text{O}(n\log{n})$$ | Log-Linear Time Complexity  |
| $$\text{O}({n}^2)$$    | Quadratic Time Complexity   |
| $$\text{O}(2^{n})$$    | Exponential Time Complexity |
| $$\text{O}({n}!)$$     | Factorial Time Complexity   |

- Asymptotic notations are mathematical notations which are used to describe the running time of an algorithm when input tends towards infinity.
  - The goal is to identify a sweet spot of granularity for reasoning about algorithms
  - We want to suppress second-order details like constant factors and lower-order terms, and focus on how the running time of an algorithm scales as the input size grows.


